{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ebc0550-0dd4-4c81-861a-e1a065231306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6af42825-0ef2-4773-b5d4-6fd9f36e235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "FOLD = range(5)\n",
    "MRI_TYPES = ['flair','t1','t1ce','t2']\n",
    "PREDICTION_PATH = './predictions/ET_90_90_90'\n",
    "LABEL_PATH = './train_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa5455fe-8cc7-4ac0-905c-91f2d208014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_split(label_path):\n",
    "    train_df = pd.read_csv(label_path,dtype = {'BraTS21ID':'str','MGMT_value':'int'})\n",
    "    index_name = train_df[(train_df['BraTS21ID'] == '00109') | (train_df['BraTS21ID'] == '00123') | (train_df['BraTS21ID'] == '00709')].index\n",
    "    train_df = train_df.drop(index_name).reset_index(drop=True)\n",
    "\n",
    "    X = train_df['BraTS21ID'].values\n",
    "    y = train_df['MGMT_value'].values\n",
    "    \n",
    "    kfold =  StratifiedKFold(n_splits=5,shuffle = True,random_state = SEED)\n",
    "    return X,y,list(kfold.split(X,y))\n",
    "\n",
    "\n",
    "def average_predictions(mri_types,fold):\n",
    "    df = pd.read_csv(f'{PREDICTION_PATH}/{mri_types[0]}/{mri_types[0]}_fold{fold}.csv')\n",
    "    id_column = df['BraTS21ID'].values\n",
    "    sum_column = df['MGMT_value']\n",
    "    \n",
    "    for mri_type in mri_types[1:]:\n",
    "        df = pd.read_csv(f'{PREDICTION_PATH}/{mri_type}/{mri_type}_fold{fold}.csv')\n",
    "        sum_column += df['MGMT_value']\n",
    "        \n",
    "    probs = (sum_column.values)/4\n",
    "    df_average = pd.DataFrame({'BraTS21ID':id_column,'MGMT_value':probs})\n",
    "    \n",
    "    _,y,SPLIT = get_train_valid_split(LABEL_PATH)\n",
    "    _,valid_idx = SPLIT[fold]\n",
    "    y_valid = y[valid_idx]\n",
    "    \n",
    "    auc = roc_auc_score(y_valid, probs)\n",
    "    preds = [1 if x > 0.5 else 0 for x in probs]\n",
    "    f1 = f1_score(y_valid, preds)\n",
    "    re = recall_score(y_valid, preds)\n",
    "    pr = precision_score(y_valid, preds)\n",
    "    \n",
    "    return df_average,auc,f1,re,pr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c76b2-756c-476e-8db9-dacce2176937",
   "metadata": {},
   "source": [
    "### Average Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b3d1ee7-1a8d-43cb-bd4d-3651e76ea248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.605 (0.052)</td>\n",
       "      <td>0.651 (0.059)</td>\n",
       "      <td>0.732 (0.116)</td>\n",
       "      <td>0.592 (0.037)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUC             F1         Recall      Precision\n",
       "0  0.605 (0.052)  0.651 (0.059)  0.732 (0.116)  0.592 (0.037)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def five_fold_result():\n",
    "    auc_sum = []\n",
    "    f1_sum = []\n",
    "    re_sum = []\n",
    "    pr_sum = []\n",
    "    for fold in FOLD:\n",
    "        _, auc,f1,re,pr = average_predictions(MRI_TYPES,fold)\n",
    "        auc_sum.append(auc)\n",
    "        f1_sum.append(f1)\n",
    "        re_sum.append(re)\n",
    "        pr_sum.append(pr)\n",
    "    return {'AUC':f'{round(np.mean(auc_sum),3)} ({round(np.std(auc_sum),3)})','F1':f'{round(np.mean(f1_sum),3)} ({round(np.std(f1_sum),3)})',\\\n",
    "            'Recall':f'{round(np.mean(re_sum),3)} ({round(np.std(re_sum),3)})','Precision':f'{round(np.mean(pr_sum),3)} ({round(np.std(pr_sum),3)})'}\n",
    "\n",
    "avg_df = pd.DataFrame(five_fold_result(),index=[0])\n",
    "avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5da172c-cc3d-44c8-af95-909078b7f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(mri_types,fold):\n",
    "    df = pd.read_csv(f'{PREDICTION_PATH}/{mri_types[0]}/{mri_types[0]}_fold{fold}.csv')\n",
    "    full_df = df[['BraTS21ID']].copy()\n",
    "    full_df[f'{mri_types[0]}'] = df['MGMT_value'].values\n",
    "    \n",
    "    for mri_type in mri_types[1:]:\n",
    "        df = pd.read_csv(f'{PREDICTION_PATH}/{mri_type}/{mri_type}_fold{fold}.csv')\n",
    "        full_df[f'{mri_type}'] = df['MGMT_value'].values\n",
    "    \n",
    "    major = []\n",
    "    mri_types = ['flair','t1','t1ce','t2']\n",
    "    for index, row in full_df.iterrows():\n",
    "        postive_count = 0\n",
    "        prob_sum = 0\n",
    "        for mri_type in mri_types:\n",
    "            prob_sum += row[f'{mri_type}']\n",
    "            if row[f'{mri_type}'] > 0.5:\n",
    "                postive_count +=1\n",
    "        \n",
    "        if postive_count > 2:\n",
    "            major.append(1)\n",
    "        elif postive_count == 2:\n",
    "            if prob_sum/4 > 0.5:\n",
    "                major.append(1)\n",
    "            else:\n",
    "                major.append(0)\n",
    "        else:\n",
    "            major.append(0)\n",
    "            \n",
    "    _,y,SPLIT = get_train_valid_split(LABEL_PATH)\n",
    "    _,valid_idx = SPLIT[fold]\n",
    "    y_valid = y[valid_idx]\n",
    "    \n",
    "    auc = roc_auc_score(y_valid, major)\n",
    "    f1 = f1_score(y_valid, major)\n",
    "    re = recall_score(y_valid, major)\n",
    "    pr = precision_score(y_valid, major)\n",
    "    \n",
    "            \n",
    "    return full_df,auc,f1,re,pr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a072a-48eb-4f45-afa9-67a1264e7677",
   "metadata": {},
   "source": [
    "### Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73b59c86-acc6-4b44-b047-c9c58fb94af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575 (0.053)</td>\n",
       "      <td>0.639 (0.073)</td>\n",
       "      <td>0.719 (0.136)</td>\n",
       "      <td>0.582 (0.046)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AUC             F1         Recall      Precision\n",
       "0  0.575 (0.053)  0.639 (0.073)  0.719 (0.136)  0.582 (0.046)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def five_fold_result():\n",
    "    auc_sum = []\n",
    "    f1_sum = []\n",
    "    re_sum = []\n",
    "    pr_sum = []\n",
    "    for fold in FOLD:\n",
    "        _, auc,f1,re,pr = majority_vote(MRI_TYPES,fold)\n",
    "        auc_sum.append(auc)\n",
    "        f1_sum.append(f1)\n",
    "        re_sum.append(re)\n",
    "        pr_sum.append(pr)\n",
    "    return {'AUC':f'{round(np.mean(auc_sum),3)} ({round(np.std(auc_sum),3)})','F1':f'{round(np.mean(f1_sum),3)} ({round(np.std(f1_sum),3)})',\\\n",
    "            'Recall':f'{round(np.mean(re_sum),3)} ({round(np.std(re_sum),3)})','Precision':f'{round(np.mean(pr_sum),3)} ({round(np.std(pr_sum),3)})'}\n",
    "\n",
    "maj_df = pd.DataFrame(five_fold_result(),index=[0])\n",
    "maj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809d7e7-7c5f-4a46-8a35-8b12a36e1c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
